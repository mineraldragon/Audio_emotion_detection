{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-02-28T19:07:35.002231Z",
     "iopub.status.busy": "2022-02-28T19:07:35.001693Z",
     "iopub.status.idle": "2022-02-28T19:07:44.635043Z",
     "shell.execute_reply": "2022-02-28T19:07:44.633853Z",
     "shell.execute_reply.started": "2022-02-28T19:07:35.002123Z"
    }
   },
   "outputs": [],
   "source": [
    "#This notebook was originally copied from https://www.kaggle.com/samiaimad/ai-uni-project. \n",
    "#This copy is to make changes of my own \n",
    "#using virtual environment VoiceRec1\n",
    "#Rogier Landman 2022\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import re\n",
    "import splitfolders\n",
    "import random\n",
    "from vad import VoiceActivityDetector\n",
    "\n",
    "# librosa is a Python library for analyzing audio and music.\n",
    "import librosa\n",
    "import librosa.display\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import soundfile as sf\n",
    "import skimage\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# to play the audio files\n",
    "from IPython.display import Audio\n",
    "\n",
    "import keras\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout, BatchNormalization\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "import wave\n",
    "import pylab\n",
    "from pathlib import Path\n",
    "from scipy import signal\n",
    "from scipy.io import wavfile\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPool2D\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "import warnings\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Assigning Data Paths to Variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T19:08:16.515756Z",
     "iopub.status.busy": "2022-02-28T19:08:16.515429Z",
     "iopub.status.idle": "2022-02-28T19:08:16.521288Z",
     "shell.execute_reply": "2022-02-28T19:08:16.520485Z",
     "shell.execute_reply.started": "2022-02-28T19:08:16.515722Z"
    }
   },
   "outputs": [],
   "source": [
    "Ravdess = \"/Users/rogierlandman/from_Samsung/Machine_learning_datasets/Ravdess_audio/audio_speech_actors_01-24\"\n",
    "CremaD = \"/Users/rogierlandman/from_Samsung/Machine_learning_datasets/Crema-D_dataset/AudioWAV\"\n",
    "Tess = \"/Users/rogierlandman/from_Samsung/Machine_learning_datasets/TESS Toronto emotional speech set data/TESS Toronto emotional speech set data\"\n",
    "Savee = \"/Users/rogierlandman/from_Samsung/Machine_learning_datasets/Savee_dataset/AudioData\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Audio Classification from the ravdess-emotional-speech-audio data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T19:08:24.505542Z",
     "iopub.status.busy": "2022-02-28T19:08:24.505217Z",
     "iopub.status.idle": "2022-02-28T19:08:25.248968Z",
     "shell.execute_reply": "2022-02-28T19:08:25.247931Z",
     "shell.execute_reply.started": "2022-02-28T19:08:24.505510Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1440 entries, 0 to 1439\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Emotions   1440 non-null   object\n",
      " 1   Path       1440 non-null   object\n",
      " 2   Gender     1440 non-null   object\n",
      " 3   Intensity  1440 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 45.1+ KB\n"
     ]
    }
   ],
   "source": [
    "ravdess=glob.glob(Ravdess + \"/*/*.wav\")\n",
    "\n",
    "emotion=[]\n",
    "path=[]\n",
    "gender=[]\n",
    "intensity=[]\n",
    "for i in ravdess:\n",
    "    #print(i)\n",
    "    isplit= i.split('.')[0]\n",
    "    isplit=isplit.split('-')\n",
    "    emotion.append(int(isplit[2]))\n",
    "    gend=int(isplit[6])\n",
    "    if gend%2==0:\n",
    "        gender.append('Female')\n",
    "    else:\n",
    "        gender.append('Male')\n",
    "    intensity.append(int(isplit[3]))\n",
    "    for sp in emotion:\n",
    "        if sp==\"1\":\n",
    "            intensity.append('Normal')\n",
    "    path.append(i)\n",
    "edf=pd.DataFrame(emotion, columns=['Emotions'])\n",
    "pdf=pd.DataFrame(path, columns=['Path'])\n",
    "gdf=pd.DataFrame(gender, columns=['Gender'])\n",
    "idf=pd.DataFrame(intensity, columns=['Intensity'])\n",
    "\n",
    "ravdess_df=pd.concat([edf, pdf, gdf, idf], axis=1)\n",
    "\n",
    "ravdess_df.Emotions.replace({1:'neutral', 2:'calm', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'}, inplace=True)\n",
    "ravdess_df.Intensity.replace({1:'Normal', 2:'Strong'}, inplace=True)\n",
    "ravdess_df.head()\n",
    "ravdess_df.isnull()\n",
    "ravdess_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Audio Classification from the cremad data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T19:08:41.078395Z",
     "iopub.status.busy": "2022-02-28T19:08:41.077158Z",
     "iopub.status.idle": "2022-02-28T19:08:41.865205Z",
     "shell.execute_reply": "2022-02-28T19:08:41.864178Z",
     "shell.execute_reply.started": "2022-02-28T19:08:41.078330Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7442 entries, 0 to 7441\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Emotions   7442 non-null   object\n",
      " 1   Path       7442 non-null   object\n",
      " 2   Gender     7442 non-null   object\n",
      " 3   Intensity  7441 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 232.7+ KB\n"
     ]
    }
   ],
   "source": [
    "crema=glob.glob(CremaD + \"/*.wav\")\n",
    "\n",
    "emotion=[]\n",
    "path=[]\n",
    "gender=[]\n",
    "intensity=[]\n",
    "for f in crema:\n",
    "    part2= Path(f).stem\n",
    "    part2=part2.split('_')\n",
    "    #print(part2)\n",
    "    if int(part2[0])%2==0:\n",
    "        gender.append('Female')\n",
    "    else:\n",
    "        gender.append('Male')\n",
    "        \n",
    "    if part2[2] == 'SAD':\n",
    "        emotion.append('sad')\n",
    "    elif part2[2] == 'ANG':\n",
    "        emotion.append('angry')\n",
    "    elif part2[2] == 'DIS':\n",
    "        emotion.append('disgust')\n",
    "    elif part2[2] == 'FEA':\n",
    "        emotion.append('fear')\n",
    "    elif part2[2] == 'HAP':\n",
    "        emotion.append('happy')\n",
    "    elif part2[2] == 'NEU':\n",
    "        emotion.append('neutral')\n",
    "    else:\n",
    "        emotion.append('Unknown')\n",
    "        \n",
    "    if part2[3]=='HI':\n",
    "        intensity.append('High')\n",
    "    elif part2[3]=='LO':\n",
    "        intensity.append('Low')\n",
    "    elif part2[3]=='MD':\n",
    "        intensity.append('Medium')\n",
    "    elif part2[3]=='XX':\n",
    "        intensity.append('Unspecified')\n",
    "        \n",
    "    path.append(f)\n",
    "    \n",
    "edf=pd.DataFrame(emotion, columns=['Emotions'])\n",
    "pdf=pd.DataFrame(path, columns=['Path'])\n",
    "gdf=pd.DataFrame(gender, columns=['Gender'])\n",
    "idf=pd.DataFrame(intensity, columns=['Intensity'])\n",
    "\n",
    "crema_df=pd.concat([edf, pdf, gdf, idf], axis=1)\n",
    "crema_df.head()\n",
    "crema_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Audio Classification from the toronto-emotional-speech-set-tess data set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T19:08:50.795402Z",
     "iopub.status.busy": "2022-02-28T19:08:50.794613Z",
     "iopub.status.idle": "2022-02-28T19:08:51.361293Z",
     "shell.execute_reply": "2022-02-28T19:08:51.360402Z",
     "shell.execute_reply.started": "2022-02-28T19:08:50.795351Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2800 entries, 0 to 2799\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Emotions   2800 non-null   object\n",
      " 1   Path       2800 non-null   object\n",
      " 2   Gender     2800 non-null   object\n",
      " 3   Intensity  2800 non-null   object\n",
      "dtypes: object(4)\n",
      "memory usage: 87.6+ KB\n"
     ]
    }
   ],
   "source": [
    "tess=glob.glob(Tess + \"/*/*.wav\")\n",
    "\n",
    "emotion=[]\n",
    "path=[]\n",
    "gender=[]\n",
    "intensity=[]\n",
    "\n",
    "for i in tess:\n",
    "    part2= Path(i).stem\n",
    "    fsplit=part2.split('_')[2]\n",
    "    if fsplit=='ps':\n",
    "        emotion.append('surprise')\n",
    "    else:\n",
    "        emotion.append(fsplit)\n",
    "    gender.append('Female')\n",
    "    path.append(i)\n",
    "    intensity.append('Unspecified')\n",
    "        \n",
    "edf=pd.DataFrame(emotion, columns=['Emotions'])\n",
    "pdf=pd.DataFrame(path, columns=['Path'])\n",
    "gdf=pd.DataFrame(gender, columns=['Gender'])\n",
    "idf=pd.DataFrame(intensity, columns=['Intensity'])\n",
    "\n",
    "tess_df=pd.concat([edf, pdf, gdf, idf], axis=1)\n",
    "tess_df.head()\n",
    "tess_df.isnull()\n",
    "tess_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Audio Classification from Savee Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T19:09:04.987680Z",
     "iopub.status.busy": "2022-02-28T19:09:04.987379Z",
     "iopub.status.idle": "2022-02-28T19:09:05.093980Z",
     "shell.execute_reply": "2022-02-28T19:09:05.092873Z",
     "shell.execute_reply.started": "2022-02-28T19:09:04.987647Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 480 entries, 0 to 479\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Emotions   480 non-null    object\n",
      " 1   Path       480 non-null    object\n",
      " 2   Gender     480 non-null    object\n",
      " 3   Intensity  480 non-null    object\n",
      "dtypes: object(4)\n",
      "memory usage: 15.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Emotions</th>\n",
       "      <th>Path</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Intensity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>surprise</td>\n",
       "      <td>/Users/rogierlandman/from_Samsung/Machine_lear...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>happy</td>\n",
       "      <td>/Users/rogierlandman/from_Samsung/Machine_lear...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>fear</td>\n",
       "      <td>/Users/rogierlandman/from_Samsung/Machine_lear...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>fear</td>\n",
       "      <td>/Users/rogierlandman/from_Samsung/Machine_lear...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>neutral</td>\n",
       "      <td>/Users/rogierlandman/from_Samsung/Machine_lear...</td>\n",
       "      <td>Male</td>\n",
       "      <td>Unspecified</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Emotions                                               Path Gender  \\\n",
       "475  surprise  /Users/rogierlandman/from_Samsung/Machine_lear...   Male   \n",
       "476     happy  /Users/rogierlandman/from_Samsung/Machine_lear...   Male   \n",
       "477      fear  /Users/rogierlandman/from_Samsung/Machine_lear...   Male   \n",
       "478      fear  /Users/rogierlandman/from_Samsung/Machine_lear...   Male   \n",
       "479   neutral  /Users/rogierlandman/from_Samsung/Machine_lear...   Male   \n",
       "\n",
       "       Intensity  \n",
       "475  Unspecified  \n",
       "476  Unspecified  \n",
       "477  Unspecified  \n",
       "478  Unspecified  \n",
       "479  Unspecified  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "savee=glob.glob(Savee + \"/*/*.wav\")\n",
    "\n",
    "emotion=[]\n",
    "path=[]\n",
    "gender=[]\n",
    "intensity=[]\n",
    "\n",
    "for f in savee:\n",
    "    #dsplit = d.split(\".\")[0]\n",
    "    #llsplit=re.split('\\d+',dsplit[0])\n",
    "    #print(llsplit)\n",
    "    part2= Path(f).stem\n",
    "    elist=part2[0]\n",
    "    if elist=='a':\n",
    "        emotion.append('angry')\n",
    "    elif elist=='d':\n",
    "        emotion.append('disgust')\n",
    "    elif elist=='f':\n",
    "        emotion.append('fear')\n",
    "    elif elist=='h':\n",
    "        emotion.append('happy')\n",
    "    elif elist=='n':\n",
    "        emotion.append('neutral')\n",
    "    elif elist=='sa':\n",
    "        emotion.append('sad')\n",
    "    else:\n",
    "        emotion.append('surprise')\n",
    "    gender.append('Male')\n",
    "    path.append(f)\n",
    "    intensity.append('Unspecified')\n",
    "\n",
    "edf=pd.DataFrame(emotion, columns=['Emotions'])\n",
    "pdf=pd.DataFrame(path, columns=['Path'])\n",
    "gdf=pd.DataFrame(gender, columns=['Gender'])\n",
    "idf=pd.DataFrame(intensity, columns=['Intensity'])\n",
    "\n",
    "savee_df=pd.concat([edf, pdf, gdf, idf], axis=1)\n",
    "#savee_df.head()\n",
    "savee_df.isnull()\n",
    "savee_df.info()\n",
    "savee_df.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Combining DataFrames (ravdess_df, crema_df,tess_df, savee_df)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T19:09:26.339795Z",
     "iopub.status.busy": "2022-02-28T19:09:26.339380Z",
     "iopub.status.idle": "2022-02-28T19:09:26.372158Z",
     "shell.execute_reply": "2022-02-28T19:09:26.370986Z",
     "shell.execute_reply.started": "2022-02-28T19:09:26.339761Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 12162 entries, 0 to 12161\n",
      "Data columns (total 4 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   Emotions   12162 non-null  object\n",
      " 1   Path       12162 non-null  object\n",
      " 2   Gender     12162 non-null  object\n",
      " 3   Intensity  12161 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 380.2+ KB\n"
     ]
    }
   ],
   "source": [
    "Data_Combined = pd.concat([ravdess_df, crema_df,tess_df, savee_df], axis = 0, ignore_index = True)\n",
    "Data_Combined.isnull()\n",
    "Data_Combined.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T19:09:56.038650Z",
     "iopub.status.busy": "2022-02-28T19:09:56.038276Z",
     "iopub.status.idle": "2022-02-28T19:10:02.462663Z",
     "shell.execute_reply": "2022-02-28T19:10:02.461132Z",
     "shell.execute_reply.started": "2022-02-28T19:09:56.038611Z"
    }
   },
   "outputs": [],
   "source": [
    "x = []\n",
    "flag = 0\n",
    "\n",
    "while (flag != 2000): \n",
    "   \n",
    "    audio = wave.open(Data_Combined.iloc[flag, 1], 'r')\n",
    "    flag = flag + 1 \n",
    "    y= Data_Combined.iloc[flag, 0]\n",
    "    if (len(x)>10):\n",
    "        flag=2000    \n",
    "\n",
    "    if (y not in x):\n",
    "        signal = np.frombuffer(audio.readframes(-1), dtype=np.int16)\n",
    "        plt.figure(figsize=(12,12))\n",
    "        plot1 = plt.subplot(211)\n",
    "        plot1.set_title(Data_Combined.iloc[flag, 0])\n",
    "        plot1.plot(signal)\n",
    "        plot1.set_xlabel('time * Number of samples')\n",
    "        plot1.set_ylabel('energy')\n",
    "\n",
    "        plot2 = plt.subplot(212)\n",
    "        plot2.specgram(signal, NFFT=1024, Fs=12281, noverlap=900)\n",
    "        plot2.set_xlabel('Time')\n",
    "        plot2.set_ylabel('Frequency')\n",
    "        \n",
    "        x.append(y)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T19:10:33.779416Z",
     "iopub.status.busy": "2022-02-28T19:10:33.779079Z",
     "iopub.status.idle": "2022-02-28T19:10:33.785429Z",
     "shell.execute_reply": "2022-02-28T19:10:33.784016Z",
     "shell.execute_reply.started": "2022-02-28T19:10:33.779382Z"
    }
   },
   "outputs": [],
   "source": [
    "def stretch(data, rate):\n",
    "    return librosa.effects.time_stretch(data, rate)\n",
    "#x , sr = librosa.load(stretch(audio_data))\n",
    "#ya = stretch(x)\n",
    "#plt.figure(figsize=(14,4))\n",
    "#librosa.display.waveplot(y=ya, sr=sr)\n",
    "#Audio(ya, rate=sr)\n",
    "\n",
    "#SNR = 20*log(RMS_s/RMS_n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T19:10:39.754942Z",
     "iopub.status.busy": "2022-02-28T19:10:39.754615Z",
     "iopub.status.idle": "2022-02-28T19:10:40.160811Z",
     "shell.execute_reply": "2022-02-28T19:10:40.159129Z",
     "shell.execute_reply.started": "2022-02-28T19:10:39.754910Z"
    }
   },
   "outputs": [],
   "source": [
    "def white_noise(data,SNR):\n",
    "    RMS_s=math.sqrt(np.mean(data**2))\n",
    "    RMS_n=math.sqrt(RMS_s**2/(pow(10,SNR/10)))\n",
    "    STD_n=RMS_n\n",
    "    noise=np.random.normal(0, STD_n, data.shape[0])\n",
    "    data_noise=noise+data\n",
    "    return data_noise \n",
    "    \n",
    "#x , sr = librosa.load(audio_data)\n",
    "#ya = white_noise(x,SNR=10)\n",
    "#plt.figure(figsize=(14,4))\n",
    "#librosa.display.waveplot(y=ya, sr=sr)\n",
    "#Audio(ya, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-19T09:27:53.322418Z",
     "iopub.status.idle": "2022-01-19T09:27:53.323563Z",
     "shell.execute_reply": "2022-01-19T09:27:53.323314Z",
     "shell.execute_reply.started": "2022-01-19T09:27:53.323255Z"
    }
   },
   "outputs": [],
   "source": [
    "def shifting_time(data, sampling_rate, shift_max, shift_direction):\n",
    "    shift = np.random.randint(sampling_rate * shift_max)\n",
    "    if shift_direction == 'right':\n",
    "        shift = -shift\n",
    "    elif shift_direction == 'both':\n",
    "        direction = np.random.randint(0, 2)\n",
    "        if direction == 1:\n",
    "            shift = -shift\n",
    "    augmented_data = np.roll(data, shift)\n",
    "    # Set to silence for heading/ tailing\n",
    "    if shift > 0:\n",
    "        augmented_data[:shift] = 0\n",
    "    else:\n",
    "        augmented_data[shift:] = 0\n",
    "    return augmented_data\n",
    "\n",
    "#x , sr = librosa.load(audio_data)\n",
    "#ya = shifting_time(x,sr,shift_max=1.5,shift_direction='right')\n",
    "#plt.figure(figsize=(14,4))\n",
    "#librosa.display.waveplot(y=ya, sr=sr)\n",
    "#Audio(ya, rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-19T09:27:53.324873Z",
     "iopub.status.idle": "2022-01-19T09:27:53.325416Z",
     "shell.execute_reply": "2022-01-19T09:27:53.325215Z",
     "shell.execute_reply.started": "2022-01-19T09:27:53.325194Z"
    }
   },
   "outputs": [],
   "source": [
    "def pitch(data, sampling_rate, pitch_factor):\n",
    "    return librosa.effects.pitch_shift(data, sampling_rate, pitch_factor)\n",
    "#x , sr = librosa.load(audio_data)\n",
    "#ya = pitch(x,sr,pitch_factor=0.5)\n",
    "#plt.figure(figsize=(14,4))\n",
    "#librosa.display.waveplot(y=ya, sr=sr)\n",
    "#Audio(ya, rate=sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Spectograms images from Audio files (old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T19:12:01.018064Z",
     "iopub.status.busy": "2022-02-28T19:12:01.017775Z"
    }
   },
   "outputs": [],
   "source": [
    "# to do: \n",
    "# - make spectrograms equal size\n",
    "# - save only the data not the axes labels, ticks\n",
    "\n",
    "bad_ones = []\n",
    "\n",
    "output_path=\"/Users/rogierlandman/from_Samsung/Machine_learning_datasets/temp/\"\n",
    "if  not os.path.exists(os.path.join(output_path, 'audio-spectrograms')):\n",
    "    os.mkdir(os.path.join(output_path, 'audio-spectrograms'))\n",
    "    \n",
    "#function to get sound and frame rate info\n",
    "def get_audio_info(audio_path):\n",
    "    wav = wave.open(audio_path, 'r')\n",
    "    frames = wav.readframes(-1)\n",
    "    audio_info = pylab.frombuffer(frames, 'int16')\n",
    "    frame_rate = wav.getframerate()\n",
    "    wav.close()\n",
    "    return audio_info, frame_rate\n",
    "\n",
    "for f in range (len(Data_Combined)):\n",
    "        file_Path = f'{Data_Combined.iloc[f, 1]}'\n",
    "        #print (file_path)\n",
    "        file_stem = Path(file_Path).stem\n",
    "        #print (file_stem)\n",
    "        target_dir = f'class_{Data_Combined.iloc[f, 0]}'\n",
    "        #print (target_dir)\n",
    "        dist_dir = os.path.join(os.path.join(output_path, 'audio-spectrograms'), target_dir)\n",
    "        #print (dist_dir)\n",
    "        # ex: ./audio-spectrograms/class_fear\n",
    "        file_dist_path = os.path.join(dist_dir, file_stem)\n",
    "        #ex: ./audio-spectrograms/class_fear/03-01-06-02-02-01-10\n",
    "        \n",
    "    \n",
    "        if not os.path.exists(file_dist_path + '.png'):\n",
    "            if not os.path.exists(dist_dir):\n",
    "                os.mkdir(dist_dir)\n",
    "            file_stem = Path(file_Path).stem\n",
    "            try:\n",
    "                audio_info, frame_rate = get_audio_info(file_Path)\n",
    "                pylab.specgram(audio_info, Fs=frame_rate)\n",
    "                pylab.savefig(f'{file_dist_path}.png')\n",
    "                pylab.close()\n",
    "                print(file_Path)\n",
    "            except:\n",
    "                bad_ones.append(file_Path)\n",
    "                print('BAD: ' + file_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Spectograms images from Audio files (new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T19:12:01.018064Z",
     "iopub.status.busy": "2022-02-28T19:12:01.017775Z"
    }
   },
   "outputs": [],
   "source": [
    "# to do: \n",
    "# - make spectrograms equal size\n",
    "# - save only the data not the axes labels, ticks\n",
    "\n",
    "bad_ones = []\n",
    "\n",
    "output_path=\"/Users/rogierlandman/from_Samsung/Machine_learning_datasets/temp1/\"\n",
    "if  not os.path.exists(os.path.join(output_path, 'audio-spectrograms')):\n",
    "    os.mkdir(os.path.join(output_path, 'audio-spectrograms'))\n",
    "    \n",
    "#function to get sound and frame rate info\n",
    "def get_audio_info(audio_path):\n",
    "    wav = wave.open(audio_path, 'r')\n",
    "    frames = wav.readframes(-1)\n",
    "    audio_info = pylab.frombuffer(frames, 'int16')\n",
    "    frame_rate = wav.getframerate()\n",
    "    wav.close()\n",
    "    return audio_info, frame_rate\n",
    "\n",
    "duration = []\n",
    "for f in range (len(Data_Combined)):\n",
    "\n",
    "        file_Path = f'{Data_Combined.iloc[f, 1]}'\n",
    "        #print (file_path)\n",
    "        file_stem = Path(file_Path).stem\n",
    "        #print (file_stem)\n",
    "        target_dir = f'class_{Data_Combined.iloc[f, 0]}'\n",
    "        #print (target_dir)\n",
    "        dist_dir = os.path.join(os.path.join(output_path, 'audio-spectrograms'), target_dir)\n",
    "        #print (dist_dir)\n",
    "        # ex: ./audio-spectrograms/class_fear\n",
    "        file_dist_path = os.path.join(dist_dir, file_stem)\n",
    "        #ex: ./audio-spectrograms/class_fear/03-01-06-02-02-01-10\n",
    "        \n",
    "    \n",
    "        if not os.path.exists(file_dist_path + '.png'):\n",
    "            if not os.path.exists(dist_dir):\n",
    "                os.mkdir(dist_dir)\n",
    "            file_stem = Path(file_Path).stem\n",
    "            try:\n",
    "                #new:\n",
    "                #load audio ..\n",
    "                data, samplerate = sf.read(file_Path)\n",
    "                duration.append(len(data) * samplerate)\n",
    "                \n",
    "                #old:\n",
    "                #audio_info, frame_rate = get_audio_info(file_Path)\n",
    "                #pylab.specgram(audio_info, Fs=frame_rate)\n",
    "                #pylab.savefig(f'{file_dist_path}.png')\n",
    "                #pylab.close()\n",
    "                print(duration)\n",
    "            except:\n",
    "                bad_ones.append(file_Path)\n",
    "                print('BAD: ' + file_Path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking duration of audio samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T19:12:01.018064Z",
     "iopub.status.busy": "2022-02-28T19:12:01.017775Z"
    }
   },
   "outputs": [],
   "source": [
    "output_path=\"/Users/rogierlandman/from_Samsung/Machine_learning_datasets/temp1/\"\n",
    "    \n",
    "duration = []\n",
    "\n",
    "for f in range (len(Data_Combined)):\n",
    "    \n",
    "    file_Path = f'{Data_Combined.iloc[f, 1]}'\n",
    "\n",
    "    #load audio ..\n",
    "    data, samplerate = sf.read(file_Path)\n",
    "\n",
    "    #resample\n",
    "    duration.append(len(data) / samplerate)\n",
    "\n",
    "plt.hist(duration)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It turns out that there is quite a bit of variation in the length of audio samples and there are considerable periods of no signal (quiet) in the audio. \n",
    "\n",
    "It makes sense to try a different approach, which is to put all samples of one category together, remove quiet parts, and then re-segment into pieces of a single length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-02-28T19:12:01.018064Z",
     "iopub.status.busy": "2022-02-28T19:12:01.017775Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "angry  accumulate data\n",
      "Bad:  /Users/rogierlandman/from_Samsung/Machine_learning_datasets/TESS Toronto emotional speech set data/TESS Toronto emotional speech set data/YAF_angry/YAF_germ_angry.wav\n",
      "angry  spectrograms\n",
      "disgust  accumulate data\n",
      "disgust  spectrograms\n"
     ]
    }
   ],
   "source": [
    "def scale_minmax(X, min=0.0, max=1.0):\n",
    "    X_std = (X - X.min()) / (X.max() - X.min())\n",
    "    X_scaled = X_std * (max - min) + min\n",
    "    return X_scaled\n",
    "\n",
    "def spectrogram_image(y, sr, out, hop_length, n_mels):\n",
    "    # use log-melspectrogram\n",
    "    mels = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=n_mels,\n",
    "                                            n_fft=hop_length*2, hop_length=hop_length)\n",
    "    mels = np.log(mels + 1e-9) # add small number to avoid log(0)\n",
    "\n",
    "    # min-max scale to fit inside 8-bit range\n",
    "    img = scale_minmax(mels, 0, 255).astype(np.uint8)\n",
    "    img = np.flip(img, axis=0) # put low frequencies at the bottom in image\n",
    "    img = 255-img # invert. make black==more energy\n",
    "\n",
    "    # save as PNG\n",
    "    skimage.io.imsave(out, img)\n",
    "\n",
    "\n",
    "output_path=\"/Users/rogierlandman/from_Samsung/Machine_learning_datasets/temp1/\"\n",
    "\n",
    "target_samplerate = 22050\n",
    "hop_length = 512 # number of samples per time-step in spectrogram\n",
    "n_mels = 128 # number of bins in spectrogram. Height of image\n",
    "#desired segment length in seconds\n",
    "segment_length = 1\n",
    "segment_length_samp = np.round(segment_length * target_samplerate)  \n",
    "\n",
    "labels = ['neutral','angry','disgust','fear','happy','sad','surprise']\n",
    "labels = ['angry','disgust','fear','happy','sad','surprise']\n",
    "   \n",
    "for label in labels:\n",
    "    \n",
    "    print(label, ' accumulate data')\n",
    "    lst = []\n",
    "    cumdata = np.array(lst)\n",
    "    for f in range (len(Data_Combined)):\n",
    "    #    for f in range (3):\n",
    "\n",
    "        #print(str(f), 'of ', str(len(Data_Combined)))\n",
    "        file_Path = f'{Data_Combined.iloc[f, 1]}'\n",
    "        #file_stem = Path(file_Path).stem\n",
    "        #print(Data_Combined.iloc[f, 0])\n",
    "        tmp = Data_Combined.iloc[f, 0]\n",
    "        if(tmp == label):  \n",
    "            \n",
    "            try:\n",
    "\n",
    "                v = VoiceActivityDetector(file_Path)\n",
    "                tmp = v.detect_speech()\n",
    "\n",
    "                z = tmp.shape[0]\n",
    "\n",
    "                new_data = np.array(lst)\n",
    "\n",
    "                for i in range(0, z-1):\n",
    "                    if(tmp[i,1] == 1):\n",
    "\n",
    "                        a=int(tmp[i+1,0])\n",
    "                        b=int(tmp[i,0])\n",
    "                        data=v.data[b:a]                 \n",
    "                        new_data = np.concatenate([new_data,data])\n",
    "\n",
    "                if(new_data.size>1):        \n",
    "                    new_data=new_data.astype(float)\n",
    "                    new_data = librosa.resample(new_data, orig_sr=v.rate, target_sr=target_samplerate)\n",
    "                    c_mx = np.max(new_data) \n",
    "                    c_mn = np.min(new_data)\n",
    "                    new_data = 2 * ((new_data - c_mx) / (c_mx - c_mn)) + 1 \n",
    "\n",
    "                cumdata = np.concatenate([cumdata,new_data])\n",
    "                \n",
    "            except:\n",
    "                \n",
    "                print('Bad: ', file_Path )\n",
    "\n",
    "                \n",
    "    print(label, ' spectrograms')\n",
    "    \n",
    "    #chop into pieces\n",
    "    n_pieces = 0\n",
    "    labelstring = 'class_' + label\n",
    "    if  not os.path.exists(os.path.join(output_path,  'audio-spectrograms', labelstring)):\n",
    "        os.mkdir(os.path.join(output_path, 'audio-spectrograms', labelstring))\n",
    "\n",
    "    while(len(cumdata)>segment_length_samp):\n",
    "        n_pieces += 1\n",
    "        tmp = cumdata[:segment_length_samp]\n",
    "\n",
    "        #make spectrogram ..\n",
    "        s1 = str(n_pieces).zfill(4)\n",
    "        s2 = 'sample_' + s1 + '.png'\n",
    "        \n",
    "        target_path = os.path.join(output_path, 'audio-spectrograms',labelstring, s2)\n",
    "        spectrogram_image(tmp, target_samplerate, target_path, hop_length, n_mels)\n",
    "\n",
    "        #remove from big array ..\n",
    "        cumdata = np.delete(cumdata, np.s_[:segment_length_samp])\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rogierlandman/from_Samsung/Machine_learning_datasets/TESS Toronto emotional speech set data/TESS Toronto emotional speech set data/YAF_angry/YAF_germ_angry.wav\n"
     ]
    }
   ],
   "source": [
    "print(file_Path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v = VoiceActivityDetector(file_Path)\n",
    "str(v.rate).zfill(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6876.010319194101\n",
      "-5593.541943021665\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "72.22081632653061"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(c_mx)\n",
    "print(c_mn)\n",
    "#data= np.arange(12).reshape((3, 4))\n",
    "#print(data.ndim)\n",
    "plt.plot(cumdata)\n",
    "len(cumdata)/22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replicate directory structure ..\n",
    "inputpath = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/temp/audio-spectrograms/'\n",
    "outputpath = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/augment/spectrograms/'\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(inputpath):\n",
    "    for file in filenames:\n",
    "        tmp = os.path.join(dirpath,file)\n",
    "        p=Path(tmp)\n",
    "        print(p.parts[-2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this would be done if you augment spectrograms \n",
    "#using frequency mask and time mask\n",
    "#https://towardsdatascience.com/audio-deep-learning-made-simple-part-3-data-preparation-and-augmentation-24c6e1f6b52\n",
    "\n",
    "def freq_mask(data, F):\n",
    "        \n",
    "        v = data.shape[1] # no. of bins       \n",
    "        # apply F frequency masks to the spectrogram\n",
    "        for i in range(F):\n",
    "            f = int(np.random.uniform(0, F)) # [0, F)\n",
    "            f0 = random.randint(0, v - f) # [0, v - f)\n",
    "            data[:, f0:f0 + f, :, :] = 0          \n",
    "        return data\n",
    "    \n",
    "    \n",
    "def time_mask(data, T):\n",
    "\n",
    "    tau = data.shape[2] # time points\n",
    "    # apply T time masks to the spectrogram\n",
    "    for i in range(T):\n",
    "        t = int(np.random.uniform(0, T)) # [0, T)\n",
    "        t0 = random.randint(0, tau - t) # [0, tau - t)\n",
    "        data[:, :, t0:t0 + t, :] = 0\n",
    "    return data\n",
    "    \n",
    "\n",
    "#replicate directory structure ..\n",
    "inputpath = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/temp/audio-spectrograms/'\n",
    "outputpath = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/augment/spectrograms/'\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(inputpath):\n",
    "    structure = os.path.join(outputpath, dirpath[len(inputpath):])\n",
    "    if not os.path.isdir(structure):\n",
    "        os.mkdir(structure)\n",
    "    else:\n",
    "        print(\"Folder already exists!\")\n",
    "\n",
    "        \n",
    "#loop through spectrogram files and augment .. \n",
    "for root, directories, file in os.walk(inputpath):\n",
    "    for file in file:\n",
    "        if(file.endswith(\".png\")):\n",
    "            #load the file\n",
    "            img = Image.open(file)\n",
    "            \n",
    "            #choose frequency or time mask\n",
    "            z = random.randint(0,1)\n",
    "            #apply\n",
    "            if(z):\n",
    "                img = freq_mask(data, 10)\n",
    "            else:\n",
    "                img = time_mask(data, 10)\n",
    "            \n",
    "            #save new image\n",
    "            file_stem = Path(file).stem\n",
    "            new_name = file_stem + '_aug1.png'\n",
    "            \n",
    "            tmp = os.path.join(root,file)\n",
    "            p=Path(tmp)\n",
    "            class_dir = p.parts[-2]\n",
    "            new_path = os.path.join(outputpath, class_dir, new_name)\n",
    "            \n",
    "            #to do: save as png image\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this would be done if you augment audio but then you need time to calculate spectrograms as well\n",
    "\n",
    "#loop through wav files and augment .. \n",
    "dest_dir = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/augment/audio/'\n",
    "\n",
    "for f in range (len(Data_Combined)):\n",
    " \n",
    "    file_Path = f'{Data_Combined.iloc[f, 1]}'\n",
    "    print(file_Path)\n",
    "    x, sr = librosa.load(file_Path)\n",
    "    file_stem = Path(file_Path).stem\n",
    "\n",
    "    #pick value for pitch shift\n",
    "    pick = random.uniform(-1,1)\n",
    "    x = pitch(x,sr, pitch_factor = pick)\n",
    "\n",
    "    #pick value for time shift\n",
    "    pick = random.uniform(0,0.5)\n",
    "    x = shifting_time(x,sr,shift_max=pick,shift_direction='both')\n",
    "\n",
    "    #pick value for time shift\n",
    "    pick = random.uniform(0,5)\n",
    "    x = white_noise(x,SNR=pick)\n",
    "\n",
    "    #pick value for time stretch\n",
    "    pick = random.uniform(0,0.8)\n",
    "    x = stretch(x, pick)\n",
    "\n",
    "    target_dir = f'class_{Data_Combined.iloc[f, 0]}'\n",
    "    dest_dir1 = os.path.join(dest_dir, target_dir)\n",
    "    dest_path = os.path.join(dest_dir1, file_stem + '_aug1.wav')\n",
    "\n",
    "    if not os.path.exists(dest_dir1):\n",
    "        os.mkdir(dest_dir1)\n",
    "\n",
    "\n",
    "    sf.write(dest_path, ya, sr, 'PCM_16')\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data Preparation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-19T09:27:53.327644Z",
     "iopub.status.idle": "2022-01-19T09:27:53.328039Z",
     "shell.execute_reply": "2022-01-19T09:27:53.327885Z",
     "shell.execute_reply.started": "2022-01-19T09:27:53.327869Z"
    }
   },
   "outputs": [],
   "source": [
    "# Declare constants\n",
    "image_h = 256\n",
    "image_w = 256\n",
    "batch_size = 32\n",
    "num_channel = 3\n",
    "num_classes = 10\n",
    "INPUT_DIR = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/temp/audio-spectrograms/'\n",
    "OUTPUT_DIR = '/Users/rogierlandman/from_Samsung/Machine_learning_datasets/temp/output/'\n",
    "\n",
    "splitfolders.ratio(INPUT_DIR, output=OUTPUT_DIR,\n",
    "    seed=1337, ratio=(.8, .1, .1), group_prefix=None, move=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-19T09:27:53.327644Z",
     "iopub.status.idle": "2022-01-19T09:27:53.328039Z",
     "shell.execute_reply": "2022-01-19T09:27:53.327885Z",
     "shell.execute_reply.started": "2022-01-19T09:27:53.327869Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dataset training spectrograms\n",
    "training_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                                             batch_size=batch_size,\n",
    "                                             validation_split=None,\n",
    "                                             directory=os.path.join(OUTPUT_DIR, 'train'),\n",
    "                                             shuffle=True,\n",
    "                                             color_mode='rgb',\n",
    "                                             image_size=(image_h, image_w),\n",
    "                                             subset=None,\n",
    "                                             seed=0)\n",
    "\n",
    "# dataset validation spectrograms\n",
    "validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                                             batch_size=batch_size,\n",
    "                                             validation_split=None,\n",
    "                                             directory=os.path.join(OUTPUT_DIR, 'val'),\n",
    "                                             shuffle=True,\n",
    "                                             color_mode='rgb',\n",
    "                                             image_size=(image_h, image_w),\n",
    "                                             subset=None,\n",
    "                                             seed=0)\n",
    "\n",
    "# dataset test spectrograms\n",
    "test_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "                                             batch_size=batch_size,\n",
    "                                             validation_split=None,\n",
    "                                             directory=os.path.join(OUTPUT_DIR, 'test'),\n",
    "                                             shuffle=True,\n",
    "                                             color_mode='rgb',\n",
    "                                             image_size=(image_h, image_w),\n",
    "                                             subset=None,\n",
    "                                             seed=0)\n",
    "\n",
    "# dataset validation spectrogram\n",
    "#validation_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "#                                             batch_size=batch_size,\n",
    "#                                             validation_split=0.2,\n",
    "#                                             directory=os.path.join(OUTPUT_DIR, 'audio-spectrograms'),\n",
    "#                                             shuffle=True,\n",
    "#                                             color_mode='rgb',\n",
    "#                                             image_size=(image_h, image_w),\n",
    "#                                             subset=\"validation\",\n",
    "#                                             seed=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-19T09:27:53.328865Z",
     "iopub.status.idle": "2022-01-19T09:27:53.329247Z",
     "shell.execute_reply": "2022-01-19T09:27:53.329108Z",
     "shell.execute_reply.started": "2022-01-19T09:27:53.329092Z"
    }
   },
   "outputs": [],
   "source": [
    "def prepare(ds):\n",
    "    # Define our one transformation\n",
    "    rescale = tf.keras.Sequential([tf.keras.layers.experimental.preprocessing.Rescaling(1./255)])\n",
    "    ds = ds.map(lambda x, y: (rescale(x, training=True), y))\n",
    "    return ds\n",
    "\n",
    "training_dataset = prepare(training_dataset)\n",
    "validation_dataset = prepare(validation_dataset)\n",
    "test_dataset = prepare(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-19T09:27:53.329994Z",
     "iopub.status.idle": "2022-01-19T09:27:53.331385Z",
     "shell.execute_reply": "2022-01-19T09:27:53.33107Z",
     "shell.execute_reply.started": "2022-01-19T09:27:53.331027Z"
    }
   },
   "outputs": [],
   "source": [
    "model=tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Input(shape=(image_h,image_w,num_channel)))\n",
    "#convolution layer\n",
    "model.add(tf.keras.layers.Conv2D(32,3,strides=2,padding='same',activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#pooling layer\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "#fully connected layer\n",
    "model.add(tf.keras.layers.Flatten())\n",
    "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
    "model.add(tf.keras.layers.BatchNormalization())\n",
    "model.add(tf.keras.layers.Dropout(0.5))\n",
    "#output layer\n",
    "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.RMSprop(),metrics=['accuracy'],)\n",
    "\n",
    "history=model.fit(training_dataset, epochs=3, validation_data=validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-19T09:27:53.333017Z",
     "iopub.status.idle": "2022-01-19T09:27:53.333672Z",
     "shell.execute_reply": "2022-01-19T09:27:53.333487Z",
     "shell.execute_reply.started": "2022-01-19T09:27:53.333461Z"
    }
   },
   "outputs": [],
   "source": [
    "#loss graph for training and validation\n",
    "history1=history.history\n",
    "loss=history1['loss']\n",
    "values=history1['val_loss']\n",
    "epochs=range(1,len(loss)+1)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(epochs, loss, 'bo', label=\"Training loss\")\n",
    "plt.plot(epochs, values, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.status.busy": "2022-01-19T09:27:53.334778Z",
     "iopub.status.idle": "2022-01-19T09:27:53.335115Z",
     "shell.execute_reply": "2022-01-19T09:27:53.334943Z",
     "shell.execute_reply.started": "2022-01-19T09:27:53.334922Z"
    }
   },
   "outputs": [],
   "source": [
    "final_loss, final_acc=model.evaluate(test_dataset, verbose=0)\n",
    "print(\"Final loss: {0:.6f}\\n Final accuracy: {1:.6f}\".format(final_loss, final_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "oldHeight": 585.852,
   "position": {
    "height": "40px",
    "left": "738px",
    "right": "20px",
    "top": "104px",
    "width": "477px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "varInspector_section_display": "none",
   "window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
